{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tweets are upload as CSV file into the jupyter notebook using read_csv function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>Polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#1255(HASH) 2/10/2015(C) 21:00:57(C) unikl(N) ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#TipsMasukU(HASH) unifi(KNK) broadband(KN) bro...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#TipsMasukUiTM(HASH) pergi(KK) library(N) uitm...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#TM(HASH) mengumumkan(KK) gangguan(KA) #intern...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#TMConnect#Streamyx(HASH) sudah(KT) agak(KT) b...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>#Unifi slow gila babeng.</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>#unifi(HASH) #admin(HASH) #sobsob(HASH) unifi(...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>#unifi(HASH) vip(N) 20(D) lagging(VB) gila(KA)...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>@__diba(MEN) then(ADV) kamu(N) belanja(N) pasa...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>@__ji95(MEN) hi(N) @=*=@ you(ADV) sudah(KT) cu...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>@__Sopheaaa Kalau unifi memang .  Sejak dua ti...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>@_ahmadakim(MEN) streamyx(KNK) @=*=@ Umobile(N...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>@_ahmadakim(MEN) streamyx(KNK) @=*=@ Umobile(N...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>@_atiqahnajihah_(MEN) pasang(KK) streamyx(KNK)...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>@_emint_(MEN) @twt_bola(MEN) @aliff_paan(MEN) ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>@_farisdanial slm..minat nak komisyen unifi/st...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>@_farisdanial unifi smpa klate dh ko pok cik</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>@_farisdanial(MEN) salam(KK) @=*=@ minat(N) he...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>@_gulaaa Hi. Untuk OKU pakej, you boleh rujuk ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>@_iamfaziean(MEN) mesti(KT) line(KN) gosip(N) ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>@_muhammad_hafiz unifi kt umah sewa ak haha. 1...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>@_nurulsha(MEN) abu(N) to(TO) unifi(KNK) cakap...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>@_redzwan cite dia unifi tak sampai kat bandar...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>@_siggplus(MEN) dekat(KT) sini(KT) unifi(KNK) ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>@0SalmanFaris0(MEN) mat(N) streamyx(KNK) bagi(...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>@1Obefiend(MEN) streamyx(KNK) putus-putus(KT) ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>@AatYasin(MEN) cable(KN) tidak(KF) kuat(KA) br...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>@aazraai(MEN) rumah(N) saya(N) unifi(KNK) teng...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>@aazrinzainal Hi. Macam mana dengan UniFi you ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>@AbangLongPirate(MEN) tidak(KF) support(N) bos...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970</th>\n",
       "      <td>Wojik beci ko buffering. Bunyi jah unifi. Unif...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1971</th>\n",
       "      <td>worst(ADV) betul(KA) maxis(N) dekat(KT) sini(K...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1972</th>\n",
       "      <td>Wow harini unifi super lembab.</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1973</th>\n",
       "      <td>ya(KT) sahaja(KT) streamyx(KNK) ini(KT) credit...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1974</th>\n",
       "      <td>yang(KT) complain(VB) tv3(C) tidak(KF) high_de...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1975</th>\n",
       "      <td>yes(ADV) ini(KT) cara(N) datuk(N) kamu(N) oran...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1976</th>\n",
       "      <td>you(ADV) are(VB) testing(VB) me(ADV) @=*=@ hen...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1977</th>\n",
       "      <td>yuran(N) semester(N) buku(N) rumah(N) sewa(N) ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>zahid(N) pesan(KK) jangan(KT) lupa(KK) tidur(K...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>@TMConnects unifi area seri kembangan memang a...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>@TMConnects xde no. Order pn dia bg..dia call ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>Pakej UniFi terbaru dengan kelajuan 30Mbps dar...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1982</th>\n",
       "      <td>berita baik  kompeni spore nak ofer internet 1...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1983</th>\n",
       "      <td>Hi @TMConnects. Saya pergi ke TMPoint last Thu...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984</th>\n",
       "      <td>@amir_aliffullah unifi ada lagi tak?</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985</th>\n",
       "      <td>bagus betol Unifi ni buat bisnes. pakej VIP 5,...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986</th>\n",
       "      <td>@manlambong Selamat pagi. Ada apa-apa perkemba...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987</th>\n",
       "      <td>@matni01 Hi. Fyi, tiada caj tambahan dikenakan...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>Unifi ni kalau time ada benda penting mesti di...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989</th>\n",
       "      <td>member2 sekali dgn pakwe member2 aku heret jd ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990</th>\n",
       "      <td>@adanmika bp mana ada unifi dan #s4dlyf3</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991</th>\n",
       "      <td>@amirrrrahimi ye lah ?? guna unifi kee</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992</th>\n",
       "      <td>Baik pasang unifi je, donlot belu pun laju. ht...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>Nak main DotA, tengok2 update sampai 1 gb lebi...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>@aishah_yuki @Farahharis kami kan trio pengawa...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>Balik bangi ni igt nk buat assignment..unifi l...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>homesick sbb rindu unifi je????hehe</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>@ninjaclawtina ???? asuh auntie masang unifi</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>@TMConnects pertanyaan bila TM akan memberi pe...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>Unifi ada tak guna la weh kalau tak reti nak t...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Tweets  Polarity\n",
       "0     #1255(HASH) 2/10/2015(C) 21:00:57(C) unikl(N) ...  positive\n",
       "1     #TipsMasukU(HASH) unifi(KNK) broadband(KN) bro...  positive\n",
       "2     #TipsMasukUiTM(HASH) pergi(KK) library(N) uitm...  positive\n",
       "3     #TM(HASH) mengumumkan(KK) gangguan(KA) #intern...  negative\n",
       "4     #TMConnect#Streamyx(HASH) sudah(KT) agak(KT) b...  positive\n",
       "5                              #Unifi slow gila babeng.  negative\n",
       "6     #unifi(HASH) #admin(HASH) #sobsob(HASH) unifi(...  positive\n",
       "7     #unifi(HASH) vip(N) 20(D) lagging(VB) gila(KA)...  positive\n",
       "8     @__diba(MEN) then(ADV) kamu(N) belanja(N) pasa...  positive\n",
       "9     @__ji95(MEN) hi(N) @=*=@ you(ADV) sudah(KT) cu...  negative\n",
       "10    @__Sopheaaa Kalau unifi memang .  Sejak dua ti...  negative\n",
       "11    @_ahmadakim(MEN) streamyx(KNK) @=*=@ Umobile(N...  negative\n",
       "12    @_ahmadakim(MEN) streamyx(KNK) @=*=@ Umobile(N...  positive\n",
       "13    @_atiqahnajihah_(MEN) pasang(KK) streamyx(KNK)...  negative\n",
       "14    @_emint_(MEN) @twt_bola(MEN) @aliff_paan(MEN) ...  negative\n",
       "15    @_farisdanial slm..minat nak komisyen unifi/st...  positive\n",
       "16         @_farisdanial unifi smpa klate dh ko pok cik  positive\n",
       "17    @_farisdanial(MEN) salam(KK) @=*=@ minat(N) he...  positive\n",
       "18    @_gulaaa Hi. Untuk OKU pakej, you boleh rujuk ...  positive\n",
       "19    @_iamfaziean(MEN) mesti(KT) line(KN) gosip(N) ...  positive\n",
       "20    @_muhammad_hafiz unifi kt umah sewa ak haha. 1...  positive\n",
       "21    @_nurulsha(MEN) abu(N) to(TO) unifi(KNK) cakap...  negative\n",
       "22    @_redzwan cite dia unifi tak sampai kat bandar...  negative\n",
       "23    @_siggplus(MEN) dekat(KT) sini(KT) unifi(KNK) ...  positive\n",
       "24    @0SalmanFaris0(MEN) mat(N) streamyx(KNK) bagi(...  negative\n",
       "25    @1Obefiend(MEN) streamyx(KNK) putus-putus(KT) ...  negative\n",
       "26    @AatYasin(MEN) cable(KN) tidak(KF) kuat(KA) br...  negative\n",
       "27    @aazraai(MEN) rumah(N) saya(N) unifi(KNK) teng...  negative\n",
       "28    @aazrinzainal Hi. Macam mana dengan UniFi you ...  negative\n",
       "29    @AbangLongPirate(MEN) tidak(KF) support(N) bos...  negative\n",
       "...                                                 ...       ...\n",
       "1970  Wojik beci ko buffering. Bunyi jah unifi. Unif...  negative\n",
       "1971  worst(ADV) betul(KA) maxis(N) dekat(KT) sini(K...  positive\n",
       "1972                     Wow harini unifi super lembab.  negative\n",
       "1973  ya(KT) sahaja(KT) streamyx(KNK) ini(KT) credit...  negative\n",
       "1974  yang(KT) complain(VB) tv3(C) tidak(KF) high_de...  positive\n",
       "1975  yes(ADV) ini(KT) cara(N) datuk(N) kamu(N) oran...  positive\n",
       "1976  you(ADV) are(VB) testing(VB) me(ADV) @=*=@ hen...  negative\n",
       "1977  yuran(N) semester(N) buku(N) rumah(N) sewa(N) ...  positive\n",
       "1978  zahid(N) pesan(KK) jangan(KT) lupa(KK) tidur(K...  positive\n",
       "1979  @TMConnects unifi area seri kembangan memang a...  positive\n",
       "1980  @TMConnects xde no. Order pn dia bg..dia call ...  positive\n",
       "1981  Pakej UniFi terbaru dengan kelajuan 30Mbps dar...  positive\n",
       "1982  berita baik  kompeni spore nak ofer internet 1...  positive\n",
       "1983  Hi @TMConnects. Saya pergi ke TMPoint last Thu...  positive\n",
       "1984               @amir_aliffullah unifi ada lagi tak?  positive\n",
       "1985  bagus betol Unifi ni buat bisnes. pakej VIP 5,...  positive\n",
       "1986  @manlambong Selamat pagi. Ada apa-apa perkemba...  positive\n",
       "1987  @matni01 Hi. Fyi, tiada caj tambahan dikenakan...  positive\n",
       "1988  Unifi ni kalau time ada benda penting mesti di...  positive\n",
       "1989  member2 sekali dgn pakwe member2 aku heret jd ...  positive\n",
       "1990           @adanmika bp mana ada unifi dan #s4dlyf3  positive\n",
       "1991             @amirrrrahimi ye lah ?? guna unifi kee  positive\n",
       "1992  Baik pasang unifi je, donlot belu pun laju. ht...  positive\n",
       "1993  Nak main DotA, tengok2 update sampai 1 gb lebi...  positive\n",
       "1994  @aishah_yuki @Farahharis kami kan trio pengawa...  positive\n",
       "1995  Balik bangi ni igt nk buat assignment..unifi l...  positive\n",
       "1996                homesick sbb rindu unifi je????hehe  positive\n",
       "1997       @ninjaclawtina ???? asuh auntie masang unifi  positive\n",
       "1998  @TMConnects pertanyaan bila TM akan memberi pe...  positive\n",
       "1999  Unifi ada tak guna la weh kalau tak reti nak t...  positive\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"MalayTweets.csv\")\n",
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Info() function is used to get the summarization of the data uploaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 2 columns):\n",
      "Tweets      2000 non-null object\n",
      "Polarity    2000 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 31.3+ KB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "head() function is used to show the rows in the data. Top 5 rows of the data are returned by default. The parameter is set to 10, to return 10 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    #1255(HASH) 2/10/2015(C) 21:00:57(C) unikl(N) ...\n",
       "1    #TipsMasukU(HASH) unifi(KNK) broadband(KN) bro...\n",
       "2    #TipsMasukUiTM(HASH) pergi(KK) library(N) uitm...\n",
       "3    #TM(HASH) mengumumkan(KK) gangguan(KA) #intern...\n",
       "4    #TMConnect#Streamyx(HASH) sudah(KT) agak(KT) b...\n",
       "5                             #Unifi slow gila babeng.\n",
       "6    #unifi(HASH) #admin(HASH) #sobsob(HASH) unifi(...\n",
       "7    #unifi(HASH) vip(N) 20(D) lagging(VB) gila(KA)...\n",
       "8    @__diba(MEN) then(ADV) kamu(N) belanja(N) pasa...\n",
       "9    @__ji95(MEN) hi(N) @=*=@ you(ADV) sudah(KT) cu...\n",
       "Name: Tweets, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(10)['Tweets']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tweets are preprocessed using RegEx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def process_tweet(Tweets):\n",
    "    return \" \".join(re.sub(\"\\([A-Za-z]+\\)|\\@\\=\\*\\=\\@\", \" \",Tweets.lower()).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['Tweets'] = train_data['Tweets'].apply(process_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>Polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#1255 2/10/2015 21:00:57 unikl bila hendak upg...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#tipsmasuku unifi broadband broadband semua ma...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#tipsmasukuitm pergi library uitm nescaya ada ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#tm mengumumkan gangguan #internet perlahan se...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#tmconnect#streamyx sudah agak besok cuti panj...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Tweets  Polarity\n",
       "0  #1255 2/10/2015 21:00:57 unikl bila hendak upg...  positive\n",
       "1  #tipsmasuku unifi broadband broadband semua ma...  positive\n",
       "2  #tipsmasukuitm pergi library uitm nescaya ada ...  positive\n",
       "3  #tm mengumumkan gangguan #internet perlahan se...  negative\n",
       "4  #tmconnect#streamyx sudah agak besok cuti panj...  positive"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train_test_split() function is used to split the Tweets into train and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(train_data[\"Tweets\"], train_data[\"Polarity\"], test_size = 0.2, random_state = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Malay stop words to eliminate stop words in the Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stop_words(stop_file_path):\n",
    "    \"\"\"load stop words\"\"\"\n",
    "    with open(stop_file_path, 'r', encoding = 'utf-8') as f:\n",
    "        stopwords = f.readlines()\n",
    "        stop_set = set(m.strip() for m in stopwords)\n",
    "        return frozenset(stop_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = get_stop_words(\"Malay_stopwords.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozenset({'media', 'global', 'negara-negara', 'proses', 'pekerja', 'kaunter', 'islam', 'nov', 'sistem', 'awam', 'unit', 'australia', 'ini', 'mempunyai', 'diniagakan', 'perdagangan', 'jun', 'penerbangan', 'menjadi', 'peningkatan', 'mohd', 'pinjaman', 'maklumat', 'tengah', 'perusahaan', 'bhd', 'barangan', 'terdapat', 'kumpulan', 'perkara', 'dari', 'menggalakkan', 'pada', 'derivatives', 'ditutup', 'utama', 'lumpur', 'katanya', 'ketua', 'syarikat', 'merosot', 'kemudahan', 'untuk', 'paras', 'akhbar', 'sekuriti', 'sebelumnya', 'apabila', 'amerika', 'april', 'terbuka', 'langkah', 'mana', 'bahan', 'kenyataan', 'negeri', 'tempoh', 'okt', 'tiga', 'wang', 'kata', 'jumaat', 'sudah', 'melihat', 'kesihatan', 'eksport', 'bulan', 'dr', 'lebih', 'sementara', 'tan', 'berubah', 'tanah', 'timur', 'sebarang', 'parlimen', 'baik', 'jumlah', 'kuasa', 'najib', 'dana', 'mengenai', 'pembangunan', 'baru-baru', 'ramai', 'pilihan', 'mendapatkan', 'modal', 'kini', 'prestasi', 'amat', 'sokongan', 'walaupun', 'menarik', 'pengerusi', 'pembinaan', 'selatan', 'ke', 'belum', 'kerajaan', 'tidak', 'mudah', 'mesyuarat', 'thailand', 'enam', 'makanan', 'kerana', 'lima', 'isu', 'kadar', 'terbang', 'jepun', 'satu', 'melalui', 'pegawai', 'memandangkan', 'kereta', 'pemberita', 'minyak', 'penting', 'supaya', 'kira-kira', 'masih', 'dunia', 'penduduk', 'mengikut', 'kenaikan', 'bank', 'di', 'sen', 'dagangan', 'minat', 'eksekutif', 'berkaitan', 'dibuka', 'membawa', 'apa', 'sebelum', 'sesi', 'antara', 'rendah', 'sebanyak', 'mendapat', 'perniagaan', 'pendidikan', 'papan', 'industri', 'tahun', 'lepas', 'kedua-dua', 'pengarah', 'tempatan', 'peratus', 'awal', 'pameran', 'pasaran', 'pula', 'kedua', 'pusat', 'setiausaha', 'kali', 'sabah', 'pelaburan', 'lot', 'menerima', 'mei', 'datuk', 'timbalan', 'ia', 'perkhidmatan', 'indeks', 'kecil', 'mac', 'mahu', 'berjumlah', 'sdn', 'pertumbuhan', 'india', 'menunjukkan', 'jawatankuasa', 'sedang', 'mencatatkan', 'sukan', 'hubungan', 'perladangan', 'dua', 'menawarkan', 'para', 'feb', 'cadangan', 'polis', 'bahawa', 'ahmad', 'depan', 'manakala', 'dengan', 'sejak', 'atas', 'bekas', 'asing', 'seluruh', 'membolehkan', 'berkenaan', 'selama', 'pasukan', 'sini', 'turut', 'tetapi', 'dasar', 'serantau', 'berdasarkan', 'operasi', 'datang', 'semakin', 'pendapatan', 'ogos', 'wanita', 'diadakan', 'hasil', 'kerjasama', 'peniaga', 'pihak', 'malam', 'berakhir', 'julai', 'indonesia', 'iaitu', 'meningkat', 'projek', 'pengeluaran', 'mata', 'baharu', 'lain', 'sawit', 'terus', 'seri', 'bagaimanapun', 'paling', 'boleh', 'syed', 'acara', 'pelabur', 'tindakan', 'mencapai', 'turun', 'sektor', 'proton', 'tinggi', 'pengguna', 'bernilai', 'juga', 'dolar', 'rantau', 'ringgit', 'jan', 'malaysia', 'orang', 'bernama', 'peserta', 'semula', 'bersama', 'sri', 'berlaku', 'terhadap', 'keuntungan', 'mahkamah', 'disember', 'menambah', 'persekutuan', 'kuala', 'khamis', 'rakyat', 'hanya', 'selepas', 'jika', 'kementerian', 'pelanggan', 'menyaksikan', 'dicatatkan', 'negara', 'mereka', 'sidang', 'dapat', 'sehingga', 'antarabangsa', 'yang', 'umno', 'segi', 'tawaran', 'tenaga', 'bawah', 'sahaja', 'petang', 'majlis', 'bidang', 'serta', 'seperti', 'dalam', 'kalangan', 'mengurangkan', 'sarawak', 'pertubuhan', 'produk', 'sekarang', 'tempat', 'kontrak', 'meningkatkan', 'empat', 'rumah', 'sumber', 'abdul', 'suku', 'banyak', 'terbaik', 'peluang', 'telah', 'urus', 'beliau', 'laporan', 'untung', 'jualan', 'memberikan', 'komposit', 'kos', 'abdullah', 'politik', 'peringkat', 'rabu', 'tentang', 'asean', 'daripada', 'ada', 'kita', 'kerja', 'tunai', 'aktiviti', 'mengumumkan', 'kewangan', 'kekal', 'lagi', 'minggu', 'akhir', 'masing-masing', 'naik', 'hingga', 'teknologi', 'presiden', 'tahap', 'bandar', 'keadaan', 'seorang', 'baru', 'setiap', 'tanpa', 'berada', 'dis', 'semalam', 'kepentingan', 'mengadakan', 'hari', 'saya', 'keselamatan', 'memberi', 'secara', 'memastikan', 'demikian', 'as', 'masyarakat', 'menjelang', 'berharap', 'jalan', 'nilai', 'dijangka', 'china', 'menggunakan', 'bukan', 'sebahagian', 'alam', 'besar', 'adalah', 'berkata', 'tun', 'raya', 'isnin', 'keputusan', 'rakan', 'oleh', 'bermula', 'menerusi', 'menurut', 'semasa', 'dan', 'ialah', 'bn', 'luar', 'menteri', 'klci', 'pejabat', 'asia', 'pelbagai', 'berjaya', 'pagi', 'perdana', 'september', 'perjanjian', 'bilion', 'masalah', 'terbesar', 'jawatan', 'semua', 'menokok', 'sebuah', 'asas', 'kepada', 'pengurusan', 'saham', 'pemimpin', 'membuat', 'mungkin', 'kes', 'termasuk', 'pukul', 'membantu', 'ketika', 'bahagian', 'program', 'kedudukan', 'merupakan', 'pertama', 'berbanding', 'selasa', 'tiada', 'kukuh', 'hadapan', 'sama', 'menyediakan', 'susut', 'kawasan', 'juta', 'sebagai', 'bagi', 'selain', 'kami', 'parti', 'keseluruhan', 'atau', 'beberapa', 'perlu', 'mengambil', 'persidangan', 'itu', 'pelancongan', 'klibor', 'faedah', 'sepanjang', 'anak', 'masa', 'air', 'nasional', 'bursa', 'sept', 'jabatan', 'harga', 'akan', 'ekonomi', 'tersebut', 'wilayah', 'sendiri', 'berikutan', 'singapura', 'niaga', 'usaha', 'permintaan', 'dewan', 'anggota'})\n"
     ]
    }
   ],
   "source": [
    "print(stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CountVectorizer is used to convert the collection of tweets to a matrix of token counts.This implementation produces a sparse representation of the counts using scipy.sparse.csr_matrix. TfidfTransformer() is used transform the count matrix to a normalized tf-idf representation.\n",
    "\n",
    "fit_transform() is used to fit to data, then transform it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer(stop_words=stopwords)\n",
    "transformer = TfidfTransformer(norm=None,sublinear_tf=True)\n",
    "\n",
    "x_train_counts = count_vect.fit_transform(x_train)\n",
    "x_train_tfidf = transformer.fit_transform(x_train_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_counts = count_vect.transform(x_test)\n",
    "x_test_tfidf = transformer.transform(x_test_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n_estimators = The number of trees in the forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(n_estimators=200)\n",
    "model.fit(x_train_tfidf,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['negative' 'negative' 'negative' 'negative' 'positive' 'positive'\n",
      " 'positive' 'negative' 'negative' 'negative' 'negative' 'positive'\n",
      " 'negative' 'positive' 'negative' 'positive' 'positive' 'negative'\n",
      " 'negative' 'positive' 'positive' 'positive' 'negative' 'positive'\n",
      " 'negative' 'negative' 'negative' 'negative' 'positive' 'positive'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'positive'\n",
      " 'positive' 'negative' 'negative' 'positive' 'positive' 'positive'\n",
      " 'positive' 'positive' 'negative' 'positive' 'negative' 'positive'\n",
      " 'positive' 'negative' 'negative' 'negative' 'positive' 'positive'\n",
      " 'positive' 'negative' 'negative' 'positive' 'positive' 'positive'\n",
      " 'positive' 'negative' 'positive' 'negative' 'negative' 'positive'\n",
      " 'positive' 'positive' 'negative' 'negative' 'negative' 'positive'\n",
      " 'negative' 'negative' 'positive' 'positive' 'negative' 'positive'\n",
      " 'negative' 'negative' 'positive' 'positive' 'positive' 'negative'\n",
      " 'positive' 'negative' 'negative' 'positive' 'negative' 'positive'\n",
      " 'positive' 'positive' 'negative' 'negative' 'negative' 'positive'\n",
      " 'negative' 'negative' 'negative' 'positive' 'positive' 'positive'\n",
      " 'negative' 'positive' 'negative' 'positive' 'negative' 'positive'\n",
      " 'positive' 'positive' 'positive' 'negative' 'positive' 'positive'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'positive' 'negative'\n",
      " 'positive' 'negative' 'positive' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'positive' 'positive'\n",
      " 'negative' 'positive' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'positive' 'negative' 'negative' 'positive'\n",
      " 'positive' 'negative' 'positive' 'negative' 'negative' 'negative'\n",
      " 'negative' 'positive' 'negative' 'positive' 'negative' 'negative'\n",
      " 'negative' 'positive' 'negative' 'negative' 'negative' 'negative'\n",
      " 'positive' 'positive' 'negative' 'positive' 'negative' 'negative'\n",
      " 'positive' 'negative' 'negative' 'positive' 'negative' 'positive'\n",
      " 'negative' 'positive' 'positive' 'negative' 'positive' 'positive'\n",
      " 'positive' 'negative' 'negative' 'negative' 'negative' 'positive'\n",
      " 'negative' 'positive' 'positive' 'negative' 'negative' 'negative'\n",
      " 'positive' 'positive' 'negative' 'positive' 'positive' 'positive'\n",
      " 'negative' 'positive' 'negative' 'negative' 'positive' 'positive'\n",
      " 'positive' 'positive' 'negative' 'negative' 'positive' 'positive'\n",
      " 'positive' 'positive' 'positive' 'positive' 'positive' 'negative'\n",
      " 'positive' 'negative' 'negative' 'negative' 'positive' 'positive'\n",
      " 'positive' 'negative' 'positive' 'negative' 'positive' 'positive'\n",
      " 'negative' 'negative' 'positive' 'positive' 'negative' 'positive'\n",
      " 'positive' 'negative' 'negative' 'negative' 'positive' 'negative'\n",
      " 'negative' 'negative' 'negative' 'positive' 'negative' 'negative'\n",
      " 'positive' 'negative' 'positive' 'positive' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'positive' 'negative' 'negative'\n",
      " 'negative' 'negative' 'positive' 'positive' 'positive' 'positive'\n",
      " 'negative' 'positive' 'positive' 'negative' 'positive' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'positive' 'negative' 'negative' 'positive'\n",
      " 'negative' 'positive' 'positive' 'positive' 'negative' 'positive'\n",
      " 'negative' 'positive' 'negative' 'positive' 'negative' 'negative'\n",
      " 'positive' 'negative' 'positive' 'positive' 'negative' 'positive'\n",
      " 'positive' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'positive' 'positive' 'positive' 'negative' 'positive' 'negative'\n",
      " 'positive' 'positive' 'positive' 'positive' 'negative' 'positive'\n",
      " 'positive' 'negative' 'negative' 'negative' 'negative' 'positive'\n",
      " 'negative' 'negative' 'negative' 'positive' 'negative' 'negative'\n",
      " 'negative' 'negative' 'positive' 'positive' 'positive' 'positive'\n",
      " 'positive' 'negative' 'negative' 'positive' 'negative' 'negative'\n",
      " 'negative' 'positive' 'positive' 'negative' 'negative' 'positive'\n",
      " 'positive' 'negative' 'positive' 'negative' 'positive' 'negative'\n",
      " 'positive' 'negative' 'negative' 'positive' 'positive' 'positive'\n",
      " 'positive' 'positive' 'negative' 'negative' 'negative' 'positive'\n",
      " 'positive' 'negative' 'positive' 'positive' 'negative' 'positive'\n",
      " 'positive' 'positive' 'negative' 'positive' 'negative' 'negative'\n",
      " 'negative' 'positive' 'positive' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'positive' 'negative' 'positive'\n",
      " 'negative' 'negative' 'positive' 'positive']\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(x_test_tfidf)\n",
    "\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy classification score. In multilabel classification, this function computes subset accuracy: the set of labels predicted for a sample must exactly match the corresponding set of labels in y_true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.745\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
